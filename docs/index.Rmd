---
title: "Model Performance Dashboard"
output: 
        html_document:
                css: "css/markdown_template.css"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r,message=FALSE,warning=FALSE,include=FALSE}
#setup
rm(list=ls())

library(data.table)
library(ggplot2)
library(dplyr)
library(stringr)
library(flextable)
library(caret)
library(forcats)
library(officer)
library(cowplot)

setwd("/Users/tilchef/Desktop/code/football_prediction/international_football_prediction_model")

model_name <- "21Nov23"
mod <- readRDS(paste0("models/logreg_",model_name,".rds"))
today <- format(as.Date(Sys.time()),"%d%b%y")

ti_aes <- function(){
        theme(
                panel.background = element_blank()
                ,panel.grid.major = element_blank()
                ,panel.grid.minor = element_blank()
                ,panel.border = element_rect(colour="black",fill=NA)
                ,axis.text = element_text(colour="black")
                ,strip.background = element_rect(color="#277150",fill="#277150")
                ,strip.text = element_text(color="#C8F0D8",size = 14,face="bold")
                ,axis.line = element_line(color="black")
                ,axis.ticks = element_line(color="black")
                ,axis.title = element_text(color="#277150",size=12)
        )
}
```



## Version Control

```{r,results="asis",echo=FALSE}
cat(paste0("Model trained + validated on data up to: ",model_name,"\n\n\n"))

cat(paste0("Report run on: ",today,"\n\n"))
```

```{r,echo=FALSE}
roc_plot <- function(roc_data,model){
        auc <- sprintf("AUC: %s%%",roc_data[[1]]%>%
                str_replace_all("a-zA-Z","") %>% 
                as.numeric() %>%
                round(digits=2)*100) 
        
        temp <- data.table(sens=roc_data$sensitivities,spec=1-roc_data$specificities)%>%
                .[,title:=paste0(model)]%>%
                ggplot()+
                geom_line(aes(x=spec,y=sens),color="#277150")+
                ti_aes()+
                scale_y_continuous(labels = scales::percent)+
                scale_x_continuous(labels = scales::percent) +
                geom_label(data=NULL,aes(x=0.44,y=0.55,label=auc),color="#277150")+
                xlab("1 - Specificity")+
                ylab("Sensitivity")+
                geom_line(data=data.table(x=c(0,1),y=c(0,1)),aes(x=x,y=y),color="#4C4C4C",linetype=2)+
                facet_wrap(~title)
        temp
}

classification_table <- function(roc_table,model){
        temp <- roc_table %>%
                data.table()%>%
                .[,V1 := case_when(V1==paste0(model)~paste0(model),TRUE~paste0("not ",model))]%>%
                .[,V2 := case_when(V2==paste0(model)~paste0(model),TRUE~paste0("not ",model))] %>%
                .[,.(N=sum(N)),by=.(V1,V2)] %>%
                .[,outcome := V1]%>%
                .[,prediction:= V2] %>%
                .[,`:=`(V1=NULL,V2=NULL)]%>%
                dcast(prediction~outcome,value.var="N") %>%
                .[,dummy_order := case_when(str_detect(prediction,"not ")~1,TRUE~2)]%>%
                .[order(dummy_order)]%>%
                .[,dummy_order := NULL]%>%
                flextable() %>%
                set_header_labels(values=c("",paste0("not ",model),paste0(model))) %>%
                border_remove() %>%
                vline(part="all",j=2,border=fp_border(color="#277150"))%>%
                vline_right(part="all",border=fp_border(color="#277150"))%>%
                hline(part="all",i=1,border=fp_border(color="#277150"))%>%
                hline_bottom(part="all",border=fp_border(color="#277150"))%>%
                bg(part="body",j=1,bg="#277150")%>%
                bg(part="header",j=2:3,bg="#277150") %>%
                bg(part="body",j=2:3,bg="#C8F0D8") %>%
                color(part="body",j=1,color="#C8F0D8")%>%
                color(part="header",j=2:3,color="#C8F0D8")%>%
                color(part="body",j=2:3,color="#277150") %>%
                align(part="all",align="center")
        
        temp
}

```

## Background:

### Summary

The model is a multinomial log-linear model trained to classify probabilities of three outcomes: home-team win, away-team-win or tie.



### Feature Importance

```{r,echo=FALSE,warning=FALSE,message=FALSE}
mod$model %>% 
        varImp() %>% 
        tibble::rownames_to_column() %>%
        mutate(Overall = Overall/sum(Overall))%>%
        mutate(label = paste0(round(Overall*100,2),"%"))%>%
        mutate(rowname:= fct_reorder(rowname,Overall))%>%
        ggplot()+
        geom_bar(stat="identity",aes(x=rowname,y=Overall),fill="#C8F0D8")+
        geom_text(aes(x=rowname,y=Overall+0.1,label = label),colour = "#277150")+
        scale_y_continuous(labels = scales::percent)+
        ti_aes()+
        theme(axis.text.x = element_text(angle=90))+
        coord_flip()+
        scale_y_continuous(labels = scales::percent,limits=c(0,1))+
        xlab("")+
        ylab("Relative Contribution")
```

Almost 50% of prediction is driven by a single outcome (whether match was played on neutral grounds).

This relationship is intuitive, however too much contribution for a single variable. Will be investigated.

### Calibration & Sensitivity

```{r,echo=FALSE,warning=FALSE,message=FALSE}
data <- data.table(fitted = mod$model$fitted.values) %>% 
        melt(measure.vars=c("fitted.away win","fitted.tie","fitted.home win"))%>%
        .[,Outcome := case_when(variable=="fitted.away win" ~ "Away Team Wins",variable == "fitted.tie" ~ "Tie",TRUE ~ "Home Team Wins")]
        
data%>%
        ggplot()+
        geom_histogram(aes(x=value,fill=Outcome))+
        geom_text(data=data %>%.[,.(value= mean(value)),by=Outcome],aes(x=value,y=750,label=sprintf("Mean:\n%.2f%%",value*100)),color="#277150")+
        geom_text(data=data %>%.[Outcome=="Tie"]%>%.[,.(value= max(value)),by=Outcome],aes(x=value,y=750,label=sprintf("Max:\n%.2f%%",value*100)),color="#E15634")+
        theme(legend.position="none")+
        scale_fill_manual(values=c("#C8F0D8","#C8F0D8","#C8F0D8"))+
        scale_x_continuous(labels = scales::percent)+
        ti_aes()+
        facet_wrap(~Outcome,ncol=1) +
        ylab("")+
        xlab("Predicted Outcome")

```

As per actuals, the predicted values average to outcomes roughly in the order of 50%-25%-25% for Home, Away and Tie respectively.

In terms of sensitivity, both Home and Away classification models can produce outcomes with extremely high (>99%) or low (<1%) probabilities. The Tie classification model struggles to produce many high probabilities - implying that a tie is rarely the most likely outcome. 
This is also observed in exploratory data analysis, where very few variables are found to be strongly correlated with tie outcomes - and model performance, where false negative rate is high.

### Residuals

Under

## Sub-model Performance  {.tabset .tabset-pills}

### Home-win

```{r,echo=FALSE,fig.width=10}
roc <- roc_plot(mod$home_roc,"Home Team Wins")

test <- classification_table(mod$conf_test,"home win") %>%gen_grob() 
test <- plot_grid(test,NULL,nrow=2,rel_heights = c(2,3))

plot_grid(roc,NULL,test,rel_widths = c(15,1,6),nrow=1)
```

### Away-win

```{r,echo=FALSE,fig.width=10}
roc <- roc_plot(mod$away_roc,"Away Team Wins")

test <- classification_table(mod$conf_test,"away win") %>%gen_grob() 
test <- plot_grid(test,NULL,nrow=2,rel_heights = c(2,3))

plot_grid(roc,NULL,test,rel_widths = c(15,1,6),nrow=1)
```

### Tie

```{r,echo=FALSE,fig.width=10}
roc <- roc_plot(mod$tie_roc,"Tie")


test <- classification_table(mod$conf_test,"tie") %>%gen_grob() 
test <- plot_grid(test,NULL,nrow=2,rel_heights = c(2,3))

plot_grid(roc,NULL,test,rel_widths = c(15,1,6),nrow=1)
```

